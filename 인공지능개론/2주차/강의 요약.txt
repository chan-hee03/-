1주차 복습

1. 특성과 타켓을 x/y로 구분
특성으로 타겟을 예측한다.

2. 전통적/현대적 프로그래밍 차이  ~~~ (1주차 참고)

3. train-test를 분류하는 이유 : 모델을 학습시킨 후 test를 이용해 성능을 확인하려고


2주차 

train과 test는 데이터의 범주가 비슷해야한다. 편향이 일어나서는 안된다.
Generalization 데이터 일반화

ai의 핵심: 주어진 데이터의 weight와 biac의를 파악하여 새로운 데이터에도 적용시키는 것

knn : superviser(지도), 라벨을 알아내려는 목적(분류), 최근접이웃의 비율로 분
k-means : unsupervised(비지도), 그룹화하려는 목적
leg_arms: 알고리즘의 성능 상승 정도가 완만해지는 지점

numpy와 pandas's datagram
numpy: 배열(array)형태, 속도 빠름
pandas: 엑셀형태, 데이터조작이 쉬움, 속도 느림
column이 있느냐 없느냐 차이
딥러닝을 하기 위해서는 배열 형태로 데이터를 넣어줘야 한다.

모든 데이터는 숫자로 변환 해줘야 한다(머신러닝의 y값만 제외)


파일 불러오는 법 3가지 local, webdata, library
webdata 불러오기 → pd.read_csv(web주소)
엑셀 불러오기 → pd.read_excel(~)


특정칼럼을 숫자로 label encoding 변환 소스
from sklearn.preprocessing import Labelencoder

특적 칼럼 삭제 소스코드
df=df.drop('칼럼 명', axis=0/1(축방향))

실습 with titanic.csv,combined_dataset-1.xlsx
(csv/xlsx, 웹주소/로컬파일 읽기, 특정칼럼 삭제,인코딩)

데이터에 결측치가 있는지 확인하기
df.isnull()

imbalanced data인지 미리 확인, 엔코딩 전/후 확인
df['label'].value.countes()


데이터가 들어왔을 때   ***과제*** titanic 데이터로 해보기
데이터 로딩 → 결측치 확인 → 결측치 제거 → 레이블 확인(imbalaced data)
→ 불필요한 컬럼 제거 → 엔코딩(숫자화) → 5가지 분류


