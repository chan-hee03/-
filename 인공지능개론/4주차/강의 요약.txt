질문 : 왜 성능이 서로 다르게 나오는가?
train_test_split이 랜덤하게 데이터를 분류하니까

완화법 →
cross validation: 모델의 일반화, 다양한 데이터에 대응되게함
k-fold 


딥러닝에서 라벨을 숫자로 하지 않는 이유: 라벨간의 관계성을 끊기 위해서 

scalling 규모를 맞추기 위해(standard scaller만 사용할것, 혼공머신에서 확인)
overfitting, underfitting, 규제 관련 강의~
규제 :
l1 규제 : 필요없는거 다 없애기
l2 규제 : 가중치 낮추기, 도음이 될지 안될지 모르니까 조절만함

결정계수 강의
회귀: 종속변수로부터 독립변수

MSE만 쓸꺼야

회귀의 절편과 가중치 (b와 w)
b:기본값
w:가중치

특성공학 규제ridge,lasso : 규제를 가하다 스코어가 더 안올라가는 시점에 조기종료

로지스틱회귀

DT: 스무고개와 같은 방식으로 분류함
불순도,지니계수:데이터의 혼함정도

RF: DT를 여러개 사용하는것
앙상블+부트스트래핑
앙상블 : 많은 모델, 높은 정답률 높은 코스트
부트스트래핑 : 중복을 허락하며 샘플링을 여러번 뽑는것

hyperparameter : 트리의 깊이, 노드의 양, 노드당 분할의 갯수 제한 등 지정할 수 있는 파라미터
hyperparameter tunning : 좋은 ai를 얻기 위해 hyperparameter를 조절하는 것
그리드서치 : 자동으로 하이퍼파라미터 튜닝

혼공머신 6장 스킵 후 7

딥러닝 : 무조껀 numpy, 원-핫 인코딩필요
머신러닝 : 

Sequential()
model.add(Dense(10,input_shape=(13,),activation='relu'))
시그모이드 소프트맥스 캐텀우ㅏ스트리ㅓ문ㅇ??
